<!DOCTYPE html>

<html lang="en">

<head>
  <meta charset="utf-8" />

  <title>Blog | ChatAssist</title>
  <link rel="stylesheet" href="normalize.css" />
  <link rel="stylesheet" href="styles.css" />
</head>

<!-- 
    What every member did
    Update on code, links to relevant code added this week
    Update on ideas
    Plan for next week
    Blocking issues, help needed
 -->

<body>
  <div class="wrap">
    <div class="header">
      ChatAssist
      <div class="navbar">
        <a class="navbar-entry" href="./index.html">
          Home
        </a>
        <a class="navbar-entry" href="./blog.html">
          Blog
        </a>
        <a class="navbar-entry" href="./team.html">
          Team
        </a>
      </div>
    </div>
    <div class="inner-wrap">

      <div class="blog-header">Week 5: April 29 - May 3, 2019</div>
      <div class="horizontal-divider"></div>
      <div class="blog-entry">
        <div class="deliverable">
          Deliverable: Demo as seen below
        </div>
        <p>
          <span style="font-size: 1.3em"><strong>Andrew:</strong></span><br />
          The code for this work is in the _____
        </p>
        <p>
          <span style="font-size: 1.3em"><strong>James:</strong></span><br />
          The code for this work is in the _____
        </p>
        <p>
          <span style="font-size: 1.3em"><strong>Ron and Laurissa:</strong></span><br />
          This week, we had a number of technical challenges which took a long time to figure out, but managed to come
          up with and build a functional workaround (and plan for next steps) after understanding what the problems
          were. We continued to work together on this part, since our work required a lot of reading various
          documentation, finding solutions to obscure problems, and choosing the correct libraries to use, that was more
          effective with two people searching and discussing design decisions.
          <br />
          Specifically though, although we sat and wrote all the code in person together so we both wrote code for both
          parts, we can roughly ascribe the C#/Unity-side stuff to Laurissa, and the Java WebSocket server and Google
          Cloud Platform (GCP) API setup to Ron.
          <br />
          Now we will discuss the various challenges we had in more detail, and the end results we were able to produce.
        </p>
        <p>
          <strong>Running GCP code on MagicLeap / Unity</strong>
        </p>
        <p>
          As a reminder, last week we wrote working API calls to GCP in a generic C# solution in Visual Studio. This
          week, we found out that just having C# code does not mean it'll run on Unity. Unity actually runs Mono, a
          cross-platform version of C#, whereas Visual Studio uses Visual C#, which is *slightly* different.
          Unfortunately, these differences are enough to make it really difficult to run arbitrary C# libraries on
          Unity.
          <br />
          Basically, things do not compile out of the box. It's possible to make it work, but pretty complicated. We
          tried
          a variety of approaches. For example, we tried just copying the GCP packages over to Packages in the Unity
          project, but it turns out that you need to make the library you want into a Unity package, which also means
          bundling all its dependencies. Otherwise, Unity may occasionally clear out the Packages folder on its own as
          it regenerates the solution. We also tried using NuGet with Unity, but couldn't get the configurations to
          work. In the meantime, we also found out that the MagicLeap does not necessarily support the C# APIs used in
          the GCP codebase.
          <br />
          At one point we also looked at the Amazon AWS API. Unfortunately, their Unity-specific API does not support
          speech-to-text, so we would probably run into the same issues trying to use their .NET API.
          <br />
          We decided at this point that while we could invest a lot more time (already took us many hours to exhaust the
          different approaches) in getting GCP queries to run on MagicLeap by building it as a Unity package, it might
          make sense to have a standalone server handling those queries. This design choice also makes sense from a
          realistic perspective: consumer apps will typically not make API calls directly, since that would involve
          exposing the private API key to the client. Instead, most apps that use cloud APIs will send requests from
          clients to a hosted server and then run the actual queries through that server. So, it's totally reasonable
          for us to follow a similar approach.
          <br />
          Here is what we are envisioning now <strong>(we worked out this design as a team of 4,</strong> Ron made it in
          Powerpoint):
          <br />
          <img src="./design.png" />
          <br />
          <strong>Conclusion:</strong> GCP code is hard to run on MagicLeap. Instead, we've decided to go with a
          server-based approach.
        </p>
        <p>
          <strong>Setting up the client and server</strong>
        </p>
        <p>
          We decided to use WebSockets to handle client-server connections, since they seem appropriate for the
          long-held socket connections that we want to have for constantly displaying text.
          <br />
          Once again, WebSockets do not exist in native Unity code. Unity has networking code, but it does not play too
          well with non-Unity servers. We looked around at various libraries, and found that MagicLeap actually didn't
          support WebSockets at all until recently - a couple months ago - in the Lumin SDK 0.20 version that we're
          using. We found that websocket-sharp seems to suit our purposes and was confirmed to work on MagicLeap.
          <br />
          To get the library to be on Unity, we had to build it as a DLL since there is no prebuilt solution for
          Windows, which we are developing on. This meant we had to set up the MonoDevelop IDE, since websocket-sharp
          was written in Mono (which is why it plays well with Unity). After that, we were able to build a DLL file
          containing the library, and we put it in Assets/Plugins in our Unity project.
          <br />
          Once we had the DLL file working, it was just a couple of lines to get a working WebSocket client in
          Unity/MagicLeap that would connect to a WebSocket server and be able to send and receive messages.
          <br />
          We then put together a WebSocket server. We decided to use Java for this, since this is the language we're
          most familiar with since we will need to write some more networking code in the near future. We also had to
          rewrite the code for using the GCP speech-to-text API in Java.
          <br />
          At this point, we have a fully functioning connection between the MagicLeap and our server. The MagicLeap can
          send arbitrary binary strings to the server, and the server can respond with a binary string. This covers all
          the networking functionality we'll need betwen the MagicLeap and non-MagicLeap things.
          <br />
          <strong>Conclusion:</strong> We have fully working networking between the MagicLeap client and a server now!
          The MagicLeap can receive text from the server and display it. The server is getting this text by making a
          call to GCP. Next week the server will actually receive the text from other microphone clients that will individually making calls to GCP. We've found the latency is low enough to be totally acceptable.
        </p>
        <p>
          The code for our work is mostly in the <a href="https://github.com/UWRealityLab/vrcapstone19sp-team3/tree/master/apis">apis</a> folder. We also hooked up our code in ChatAssist's <a href="https://github.com/UWRealityLab/vrcapstone19sp-team3/blob/master/chatassist/ChatAssist/Assets/Scripts/SpeechToText.cs">SpeechToText.cs</a> script.
        </p>
        <p>
          <strong>Integrating our code</strong>
        </p>
        <p>
          We worked together as a team of 4 for this part. Basically, we've now tied our code together so that the
          MagicLeap is able to show arbitrary text sent to it from the server. For the sake of this mini demo we also
          wrote some code on our server to arbitrarily change the text to a user input, although that functionality
          isn't actually needed since the microphone clients will update the server with text data.
          <br />
          Here is a video showing what our project now looks like (should be embedded below but we've also put the link here):
          <br />
          <a href="https://www.youtube.com/embed/bW56ecAwUH4" target="_blank">https://www.youtube.com/embed/bW56ecAwUH4</a>
          <br />
          <iframe width="560" height="315" src="https://www.youtube.com/embed/bW56ecAwUH4" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>
        </p>
        <p>
          <span style="font-size: 1.3em"><strong>Plan for next week:</strong></span><br />
        </p>
        <p>
          We will continue to integrate our code for our demo on Thursday. Specifically...
          <br />
          Ron and Laurissa will:
          <ul>
            <li>Get the streaming speech-to-text API to work (fairly complex, streams are tough to work with)</li>
            <li>Use a microphone with the streaming API</li>
            <li>Write the microphone client and make it forward data to the server</li>
            <li>Make the server send data to the MagicLeap in a structured fashion</li>
            <li>Update the MagicLeap / Unity code to accept text updates in a structured fashion</li>
          </ul>
          We haven't totally decided how we'll split this work, but probably Ron will work on the streaming API and the basic microphone client setup, and Laurissa will work on linking that to the current server and structuring the data in some consistent way.
          <br/>
          Andrew and James will:
          <ul>
            <li>Figure out anchoring</li>
          </ul>
        </p>
      </div>

      <div class="blog-header">Week 4: April 22 - 26, 2019</div>
      <div class="horizontal-divider"></div>
      <div class="blog-entry">

        <div class="deliverable">
          Deliverable: <a href="./index.html"> Updated PRD (on Home page)</a>
        </div>

        <p>
          Ron and Laurissa:
          This week, we tested different Speech-To-Text APIs including Microsoft Azure, Amazon Transcribe,
          and Google Cloud. We tested them out by using our phone as a microphone since we haven't bought
          a proper one yet. At first, we thought that the room was too loud to pick up the exact words
          we're saying and it made us think about how when we demo our final product on our demo day,
          it might have the same amount of noise. After some trial and error, we found out that it only works
          for .flac audio files. In the example, they provided a .flac file which worked pretty well. We
          learned that we have to convert our mp3 file to a .flac file so that it is compatible with it.
          We decided to use Google's Cloud Speech-to-Text API because it supports widest
          variety of languages and contains different feature that we found useful. Some of which includes
          the language detection and multispeaker content.
        </p>

        <p>
          Andrew and James:
          We also tested different ways of generating some preliminary chat bubbles with some text in Unity.
          Right now, they are simply objects within Unity that have a fixed text in them. From what we saw,
          the text itself is a bit visible, but the visual itself still has much to be desired in terms of
          presentation to the user with respect to other objects.
          The text boxes are aligned with the camera, which can be good in some contexts with respect to our UI menu
          for setting the language of the user, as it keeps the bubble in the view of the user, but it still needs some
          more work to be better fleshed out.
          What was currently visible by the user is this...
          <figure align="center">
            <img src="imgs/week4_2.jpg" alt="Magic Leap Week 4 ChatAssist Display">
            <figcaption>Fig.1 - Magic Leap Week 4 ChatAssist Display</figcaption>
          </figure>

        </p>

        <p>
          Our current plan for next week is to order some wireless clip-on microphones so that we can test and
          we also want to get the Speech-To-Text API up and running on the Magic Leap. Additionally, we will develop
          the pipeline to generate text that can be seen by the user, play around with some of the Magic Leap examples,
          and
          develop the chat bubbles more into an actual product which can display text effectively to the user. We will
          also look
          into a way to anchor the bubble to something in the real world, ideally something that can be held by a
          person.
          We will also look into some chat box assets as well to make them look more appealing compared to what they are
          now.
          The overall goal for next week is to combine the work from our two teams to make a soft demo of ChatAssist.
        </p>

        <div class="references">
          Some useful references for this week:
          <a href="https://www.youtube.com/watch?v=SxYvufk7Hrs&feature=youtu.be">Perfect Text in Unity</a>
          <a href="https://assetstore.unity.com/search/?k=chat+box&order_by=relevance&q=chat&q=box&rows=42">Possible
            Chat Box Assets</a>
        </div>
      </div>

      <div class="blog-header">Week 3: April 15 - 19, 2019</div>
      <div class="horizontal-divider"></div>
      <div class="blog-entry">

        <div class="deliverable">
          Deliverable: <a href="./index.html">PRD (on Home page)</a>
        </div>

        <p>
          This week, we gave our project pitch in class where we talked about the problem
          we are addressing with our product, the technologies that we are planning to use,
          and a timeline of what we plan to accomplish each week. Aditya suggested that we
          use the spatial mapping mesh to physically drop the chat bubble if we were unable
          to use cameras to find some unique marker. After class, we decided to get microphones
          so that we can have more options than just relying on our devices' microphones.
        </p>
        <p>
          We completed our Product Requirements Document (PRD), which details our
          project plan with deliverables, features, performance metrics, milestones,
          responsibilities of each team member, materials and budget, risks, and how
          risks will be addressed. This can be found at the top of the 'Home' tab.
        </p>
        <p>
          We worked on the slides and PRD as a group. In the lab session, we set up
          the Magic Leap and ran into some trouble when working through the guides. We
          eventually got this cleared up and learned that we could only run our applications
          on two of the 4 computers we were given because the Magic Leap is a very
          resource-intensive device. We learned what we needed to do with the Magic Leap and
          that we needed to update it when it's charged so that it can run the applications
          we built using Unity.
        </p>
        <p>
          Our current plan for next week is to have Ron and Laurissa test out different APIs
          for speech-to-text translation and have James and Andrew display some readable
          text on the Magic Leap.
        </p>
        <p>
          One of the problems that we faced this week is that the Magic Leap gets very hot, but
          Alan told us that we should probably just close all the applications when it's not
          being used in order to make it less likely to overheat. This may prove to make the
          device less user-friendly, since people probably don't want something hot on their
          heads, so we're wondering how other people who develop on the Magic Leap deal with this.
        </p>

        <div class="references">
          Some useful references for this week:
          <a href="https://creator.magicleap.com/learn/guides/unity-setup">Setting up Unity Projects on Magic Leap</a>
          <a href="https://docs.google.com/document/d/1tEB1_UU1wg3c1qH75UlhwRIBhAvC4alidN_7Bcb5AyY/edit">Magic Leap
            set-up instructions</a>
        </div>
      </div>


      <div class="blog-header">Week 1 + 2: April 1 - 12, 2019</div>
      <div class="horizontal-divider"></div>
      <div class="blog-entry">
        <!-- 
    What every member did
    Update on code, links to relevant code added this week
    Update on ideas
    Plan for next week
    Blocking issues, help needed
 -->
        <div class="deliverable">
          Deliverable: <a href="./project_proposal.pdf">Project Proposal</a>
        </div>

        <p>
          This week, we all got together to discuss possible ideas. In class,
          we've been working on the various tutorials. We also all worked
          together on the website and project proposal.
        </p>
        <p>
          The code we wrote this week was for this website and for the
          tutorials we did in class.
        </p>
        <p>
          Originally, we thought of doing some kind of game-like simulation,
          but we weren't able to come up with a clear direction on the purpose
          of the simulation. Right now, our idea is to build a conversation
          tool that displays chat bubbles over people's heads as they speak
          and records the conversation text. It would use speech-to-text tech
          and the built-in microphones to figure out where words are coming
          from. This would be useful for people who need clear transcriptions
          of speech. For example, it could benefit people with impaired
          hearing, people who don't speak a language natively, or people in
          business meetings who want a log of the conversation.
        </p>
        <p>
          Next week, we will prepare our team pitch and figure out what
          resources and assets we need to make this project a reality.
        </p>
        <p>
          Currently, we're not stuck on anything. We're excitedly waiting to
          finish our pitch so we can start doing real work on our project!
        </p>

        <div class="references">
          Some useful references for this week:
          <a
            href="https://www.reddit.com/r/magicleap/comments/85w7tn/faq/">https://www.reddit.com/r/magicleap/comments/85w7tn/faq/</a>
          <a href="https://www.youtube.com/watch?v=GItvRqmuUME">https://www.youtube.com/watch?v=GItvRqmuUME</a>
        </div>

      </div>

    </div>
  </div>
  </div>
  </div>
</body>

</html>